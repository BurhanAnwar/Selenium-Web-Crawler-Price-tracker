# -*- coding: utf-8 -*-
"""Selenium Web Crawler â€“ Price tracker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VoL3-Jqdbv6iu6ndCkeWUFkB-uadwQqP
"""

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support import expected_conditions as EC
import time
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from lxml import html
import pandas as pd
import csv

s = Service("chromedriver.exe")
driver = webdriver.Chrome(service=s)
url = "https://om.digitalmall.app/"
driver.get(url)
time.sleep(3)

btn = driver.find_element(By.XPATH, '//*[@id="ion-overlay-1"]/language-switcher/ion-content/div/div[2]/div[2]')
driver.execute_script("arguments[0].scrollIntoView(true);", btn)
btn.click()
time.sleep(2)

btn1_xpath = 'body > app-root > ion-app > ion-router-outlet > app-tabs > ion-tabs > div.tabs-inner > ion-router-outlet > app-home > ion-content > div > category-card > div > div > div > div:nth-child(2)'
btn1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, btn1_xpath)))
driver.execute_script("arguments[0].scrollIntoView(true);", btn1)
time.sleep(2)
btn1.click()

time.sleep(2)
elements = WebDriverWait(driver, 10).until(
    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'body > app-root > ion-app > ion-router-outlet > app-inventory-types-main > ion-content > div > div.grid.grid-cols-2.md\:grid-cols-3.lg\:grid-cols-4.xl\:grid-cols-6 > div.cards'))
)

for element in elements:
    driver.execute_script("arguments[0].scrollIntoView(true);", element)
    element.click()
    time.sleep(1)

time.sleep(2)
btn2 = driver.find_element(By.CSS_SELECTOR, 'body > app-root > ion-app > ion-router-outlet > app-inventory-types-main > ion-footer > div > ion-button')
driver.execute_script("arguments[0].scrollIntoView(true);", btn2)
btn2.click()
time.sleep(5)


current_url = driver.current_url
time.sleep(5)
soup = BeautifulSoup(driver.page_source, 'html.parser')

data = []
visited_urls = set()

elements = soup.find_all(class_='ng-star-inserted')

for element in elements:
    for anchor in element.find_all('a', href=True):
        href = anchor['href']
        if not href.startswith('http'):
            href = urljoin(current_url, href)

        if href not in visited_urls:
            visited_urls.add(href)
            driver.get(href)
            time.sleep(5)

            soup = BeautifulSoup(driver.page_source, 'html.parser')
            time.sleep(5)
            title_elements = soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\\:xl\\:pl-xl.rtl\\:xl\\:pr-xl.xl\\:ms-1180.laptop\\:ms-1400.xxl\\:ms-1536.xxxl\\:ms-1920.rtl\\:xl\\:pr-4xl.rtl\\:xl\\:pl-4xl.xl\\:w-\\[30\\%\\] > div.details-head-web.flex.justify-between.items-start.flex-row-reverse > div.headings.flex-1.pt-3xl.px-xl.pb-lg.xl\\:px-none.ng-star-inserted > p.animate-slide.rtl\\:text-end.text-gray-700.leading-6.text-lg.med-family.m-0.xl\\:leading-7.xl\\:text-3xl.ng-star-inserted')
            body_ele = soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.px-xl.pb-xl.xl\:px-none.ng-star-inserted > div > div:nth-child(1) > p')
            body_element = body_ele[0].text.strip()

            model_y= soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.px-xl.pb-xl.xl\:px-none.ng-star-inserted > div > div:nth-child(2) > p')
            model_year = model_y[0].text.strip()
            trans = soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.px-xl.pb-xl.xl\:px-none.ng-star-inserted > div > div:nth-child(3) > p')
            transmission = trans[0].text.strip()
            f = soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.px-xl.pb-xl.xl\:px-none.ng-star-inserted > div > div:nth-child(4) > p')
            Fuel = f[0].text.strip()
            loc = soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.px-xl.pb-xl.xl\:px-none.ng-star-inserted > div > div:nth-child(5) > p')
            Location = loc[0].text.strip()
            p = soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.px-xl.pb-xl.xl\:px-none.ng-star-inserted > div > div:nth-child(6) > p')
            Price = p[0].text.strip()
            add_n= soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.px-xl.pb-xl.xl\:px-none.ng-star-inserted > div > div:nth-child(7) > p')
            Add_no = add_n[0].text.strip()
            pdd = soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.px-xl.pb-xl.xl\:px-none.ng-star-inserted > div > div:nth-child(8) > p')
            Publish_date = pdd[0].text.strip()
            if title_elements:
                title_text = title_elements[0].text.strip()
            else:
                title = soup.select('body > app-root > ion-app > ion-router-outlet > app-details > ion-content > div > div.left-container.overflow-scroll.h-max.ltr\:xl\:pl-xl.rtl\:xl\:pr-xl.xl\:ms-1180.laptop\:ms-1400.xxl\:ms-1536.xxxl\:ms-1920.ltr\:xl\:pr-4xl.rtl\:xl\:pl-4xl.xl\:w-\[30\%\] > div.details-head-web.flex.justify-between.items-start.flex-row-reverse > div.headings.flex-1.pt-3xl.px-xl.pb-lg.xl\:px-none.ng-star-inserted > p.animate-slide.rtl\:text-end.text-gray-700.leading-6.text-lg.med-family.m-0.xl\:leading-7.xl\:text-3xl.ng-star-inserted')
            if title:
                title_text = title[0].text.strip()


                data.append({
                  "url": href,
                  "title": title_text,
                   "body": body_element,
                   "model_year": model_year,
                  "transmission": transmission,
                   "fuel": Fuel,
                    "location": Location,
                   "price": Price,
                  "publish_date": Publish_date
                 })

for cars in data:
  df = pd.DataFrame([cars])
  df.to_csv('car_data.csv', mode='a', header=False, index=False)